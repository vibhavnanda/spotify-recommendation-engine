{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da344573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "import datetime\n",
    "from dateutil import tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5896b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importSpotifyKaggleDataset():\n",
    "    \"\"\"\n",
    "    Function definition: \n",
    "        This function imports a local version of the Spotify dataset from kaggleat. \n",
    "        This dataset can be found here: https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks\n",
    "\n",
    "    Arguments: \n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        'spotifyTracksdf' -- A dataframe containing the data from kaggle\n",
    "    \"\"\"\n",
    "\n",
    "    spotifyTracksdf = pd.read_csv('archive/tracks.csv')\n",
    "    return spotifyTracksdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e2c1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSpotifyData(dataframe,datatype=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Function definition: \n",
    "        This function performs data cleaning on the data from Spotify\n",
    "\n",
    "    Arguments: \n",
    "        'dataframe' -- Spotify dataframe containing data from Spotify\n",
    "        'datatype' -- Type of Spotify data. Could be either from the kaggle dataset or pulled from user's Spotify\n",
    "\n",
    "    Returns:\n",
    "        'dataframe' -- A dataframe containing cleaned Spotify data\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "        \n",
    "    dataframe.dropna(inplace=True)\n",
    "    dataframe.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Values in the explicit column for the data from user's Spotify is represented in false/true format. \n",
    "    This 'if' statement is used to convert values from false/true format to 0/1 format like is represented in\n",
    "    the kaggle dataset\n",
    "    \"\"\"\n",
    "    if datatype == \"user_data\": \n",
    "        dataframe['explicit'] = dataframe[\"explicit\"].astype(int)\n",
    "    \n",
    "    if datatype == \"kaggle_data\":\n",
    "        \"\"\"\n",
    "        Creating unique IDs to remove duplicate where the same song has different IDs by concatanating the following\n",
    "        1. Artist name\n",
    "        2. Name of the track\n",
    "        \n",
    "        We ONLY want to do this for the kaggle dataset and NOT the user's data because if a user has listened to the \n",
    "        same song multiple times we want that to be reflected and have some effect (bias) on the outcome\n",
    "        \"\"\"\n",
    "        dataframe['unique_id'] = dataframe.apply(lambda x: str(x['artists']) + str(x['name']) ,axis = 1)\n",
    "        dataframe.drop_duplicates('unique_id',inplace=True)\n",
    "\n",
    "        \"\"\"\n",
    "        Removing the 'unique_id' column since now all songs should be unique and\n",
    "        can be uniquely idenfitied using the 'id' column\n",
    "        \"\"\"\n",
    "        dataframe.drop(columns=['unique_id'],inplace=True)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Dropping the following columns/features since the experiment is about recommending tracks only \n",
    "    based on musical features:\n",
    "    1. Popularity\n",
    "    2. Duration\n",
    "    3. Artist Name(s)\n",
    "    4. Artists ID(s)\n",
    "    5. Release date       \n",
    "    \"\"\"\n",
    "    dataframe.drop(columns=['popularity','duration_ms','artists','id_artists',\n",
    "                            'release_date', ],\n",
    "                     inplace=True)\n",
    "    \n",
    "\n",
    "    dataframe.rename(columns={\"id\": \"track_id\", \"name\":\"track_name\"},inplace=True)\n",
    "    \n",
    "    dataframe.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    return dataframe\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef324d1",
   "metadata": {},
   "source": [
    "#### OUTLINE OF THE FEATURES NEEDED TO BE PRE-PROCESSED\n",
    "\n",
    "##### Numerical:\n",
    "\n",
    "1. acousticness (Ranges from 0 to 1)\n",
    "2. danceability (Ranges from 0 to 1)\n",
    "3. energy (Ranges from 0 to 1)\n",
    "4. instrumentalness (Ranges from 0 to 1)\n",
    "5. valence (Ranges from 0 to 1)\n",
    "6. liveness (Ranges from 0 to 1)\n",
    "7. tempo (Float typically ranging from 50 to 150)\n",
    "8. loudness (Float typically ranging from -60 to 0)\n",
    "9. speechiness (Ranges from 0 to 1)\n",
    "\n",
    "##### Categorical:\n",
    "\n",
    "10. mode (0 = Minor, 1 = Major)\n",
    "11. explicit (0 = No explicit content, 1 = Explicit content)\n",
    "12. timesignature (The predicted timesignature, most typically 4)\n",
    "13. key (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1 and so on…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d58aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessSpotifyData(dataframe, datatype = None, baselinedf = None, preDefinedScaler = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function definition: \n",
    "        This function performs data pre-processing on the cleaned Spotify data\n",
    "\n",
    "    Arguments: \n",
    "        'dataframe' -- Dataframe containing cleaned Spotify data\n",
    "        'datatype' -- Type of Spotify data. Could be either from the kaggle dataset or pulled from user's Spotify\n",
    "        'baselinedf' -- Dataframe to be used as a baseline while reindexing the newly pre-processed dataframe\n",
    "        'preDefinedScaler' -- scaler to be used while performing data scaling/normalization\n",
    "\n",
    "    Returns:\n",
    "        'processedDataframe' -- A dataframe containing pre-processed Spotify data\n",
    "        'newScaler' -- Scaler so it can be used to (only)\"transform\" the real life data points coming from \n",
    "                    users spotify. This scaler has already been \"fit\" with the data points from kaggle dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    dataframe.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    \"\"\"\n",
    "    Performing One-Hot Encoding on categorical variables. This method of encoding retains all the columns\n",
    "    in the original dataframe and adds all the new columns created after the onehot encoding process\n",
    "    \"\"\"\n",
    "    processedDataframe = pd.get_dummies(dataframe, columns = ['mode','explicit','time_signature', 'key'])\n",
    "    \n",
    "    \n",
    "    featuresToBeScaled = ['danceability', 'energy','loudness','speechiness','acousticness',\n",
    "                          'instrumentalness','liveness','valence','tempo']\n",
    "    \n",
    "    if datatype == \"kaggle_data\":\n",
    "        \n",
    "        \"\"\"\n",
    "        Performing data scaling/normalization\n",
    "        \"\"\"\n",
    "        newScaler = MinMaxScaler()\n",
    "        processedDataframe[featuresToBeScaled] = newScaler.fit_transform(processedDataframe[featuresToBeScaled])\n",
    "       \n",
    "        processedDataframe.reset_index(drop = True,inplace = True)\n",
    "        return processedDataframe, newScaler\n",
    "\n",
    "    \n",
    "    if datatype == \"user_data\": \n",
    "        \n",
    "        \"\"\"\n",
    "        Using the already \"fit\" scaler with the kaggle dataset to \"transform\" the data from users spotify\n",
    "        \"\"\"\n",
    "        processedDataframe[featuresToBeScaled] = preDefinedScaler.transform(processedDataframe[featuresToBeScaled])\n",
    "       \n",
    "       \n",
    "        \n",
    "        \"\"\"\n",
    "        This step ensures that 'user data' dataframe has the same One-Hot Encoding schema as the 'kaggle dataset'\n",
    "        dataframe. The 'kaggle dataset' is represented by the 'baselinedf\" dataframe since kaggle is the baseline. \n",
    "        \n",
    "        !NOTE!: Since 'user_listening_datetime' column doesn't exist in the dataframe representing 'kaggle dataset', \n",
    "                this reindexing step WILL loose the column 'user_listening_datetime' from the dataframe representing \n",
    "                'user data' \n",
    "        \"\"\"\n",
    "        tempUserDataFrame = processedDataframe.reindex(columns = baselinedf.columns,\n",
    "                                                        fill_value = 0)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        This step will re-add the column \"user_listening_datetime\" back to the dataframe representing 'user data'\n",
    "        \"\"\"\n",
    "        tempUserDataFrame['user_listening_datetime'] = processedDataframe['user_listening_datetime']\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        This step will convert 'user's listening date/time' to 'pandas datetime format' and then \n",
    "        extract date-only from the date/time (leaving out time)\n",
    "        \"\"\"\n",
    "        tempUserDataFrame['user_listening_datetime'] = pd.to_datetime(tempUserDataFrame['user_listening_datetime'])\n",
    "        tempUserDataFrame['user_listening_dateonly'] = pd.DatetimeIndex(tempUserDataFrame['user_listening_datetime']).date\n",
    "        \n",
    "        \n",
    "        tempUserDataFrame.drop(columns=['user_listening_datetime'],inplace=True)\n",
    "        \n",
    "        processedDataframe = tempUserDataFrame\n",
    "        \n",
    "        processedDataframe.reset_index(drop = True,inplace = True)\n",
    "        return processedDataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c17fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectToUserSpotify(spotifyClientID,spotifySecret,spotifyRedirectUri,scope):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Function definition: \n",
    "        This function connects to the users Spotify account\n",
    "\n",
    "    Arguments: \n",
    "        'spotifyClientID' -- User's Spotify client ID\n",
    "        'spotifySecret' -- User's Spotify secret\n",
    "        'spotifyRedirectUri' -- URI/URL to redirect the user to be authenticated so the user can authorize the app \n",
    "                                as the consumer of the data in the user's Spotify account\n",
    "        'scope' -- List of resources that can be be accessed by this app (scope of authorization)\n",
    "\n",
    "    Returns:\n",
    "        'sp' -- Authenticated connection to the user's Spotify\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This step will create an authentication manager object to authenticate the app. It will then make a connection\n",
    "    to the user's Spotify account\n",
    "    \"\"\"\n",
    "    authManager = SpotifyOAuth(client_id =spotifyClientID, \n",
    "                               client_secret = spotifySecret,\n",
    "                               redirect_uri = spotifyRedirectUri, \n",
    "                               scope = scope )\n",
    "    sp = spotipy.Spotify(auth_manager = authManager)\n",
    "    \n",
    "    return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb843024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSpotifyUserData(sp):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function definition: \n",
    "        This function creates a dataframe by pulling information from the user's Spotify account\n",
    "\n",
    "    Arguments: \n",
    "        'sp' -- Authenticated connection to the user's Spotify\n",
    "\n",
    "    Returns:\n",
    "        'spotifyUserDatadf' -- Dataframe created by pulling information from the user's Spotify account\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This step defines the schema of the 'spotifyUserDatadf' dataframe which will be similar to the schema of the \n",
    "    dataframe representing the 'kaggle dataset'. The only difference will be the column 'user_listening_datetime'\n",
    "    which represents the date/time when the user listening to a particular song/track\n",
    "    \"\"\"\n",
    "    spotifyUserDatadf_columnNames = ['id', 'name', 'popularity', 'duration_ms', 'explicit', 'artists',\n",
    "                               'id_artists', 'release_date', 'danceability', 'energy', 'key',\n",
    "                               'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                               'liveness', 'valence', 'tempo', 'time_signature','user_listening_datetime']\n",
    "    \n",
    "    \"\"\"\n",
    "    Declaring an empty dataframe with the predefined column names\n",
    "    \"\"\"\n",
    "    spotifyUserDatadf = pd.DataFrame(columns = spotifyUserDatadf_columnNames)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This step pull's/get's tracks from the user’s recently played track history (listening history)\n",
    "    \"\"\"\n",
    "    userPlayBackHistory = sp.current_user_recently_played(limit = 50)\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    This step will populate the 'spotifyUserDatadf' dataframe with the user's listening history information. \n",
    "    Any information that is not available in user's playback history but is a feature defined in the 'spotifyUserDatadf'\n",
    "    dataframe will be populated with a value = 'unknown'\n",
    "    \"\"\"\n",
    "    for idx, itemDict in enumerate(userPlayBackHistory['items']):\n",
    "        rowIndex = idx\n",
    "        trackDict = itemDict['track']\n",
    "\n",
    "        spotifyUserDatadf.loc[rowIndex,'id'] = trackDict['id']\n",
    "        spotifyUserDatadf.loc[rowIndex,'name'] = trackDict['name']\n",
    "        spotifyUserDatadf.loc[rowIndex,'popularity'] = trackDict['popularity']\n",
    "        spotifyUserDatadf.loc[rowIndex,'duration_ms'] = trackDict['duration_ms']\n",
    "        spotifyUserDatadf.loc[rowIndex,'explicit'] = trackDict['explicit']\n",
    "        spotifyUserDatadf.loc[rowIndex,'artists'] = trackDict['artists'][0]['name']\n",
    "        \n",
    "  \n",
    "        spotifyUserDatadf.loc[rowIndex,'id_artists'] = 'unknown' \n",
    "        spotifyUserDatadf.loc[rowIndex,'release_date'] = 'unknown'\n",
    "        \n",
    "       \n",
    "        \"\"\"\n",
    "        This step utilizes spotipy to get audio feature for the current track\n",
    "        \"\"\"\n",
    "        trackAudioFeaturesDict = sp.audio_features(trackDict['id'])[0]\n",
    "\n",
    "        spotifyUserDatadf.loc[rowIndex,'danceability'] = trackAudioFeaturesDict['danceability']\n",
    "        spotifyUserDatadf.loc[rowIndex,'energy'] = trackAudioFeaturesDict['energy']\n",
    "        spotifyUserDatadf.loc[rowIndex,'key'] = trackAudioFeaturesDict['key']\n",
    "        spotifyUserDatadf.loc[rowIndex,'loudness'] = trackAudioFeaturesDict['loudness']\n",
    "        spotifyUserDatadf.loc[rowIndex,'mode'] = trackAudioFeaturesDict['mode']\n",
    "        spotifyUserDatadf.loc[rowIndex,'speechiness'] = trackAudioFeaturesDict['speechiness']\n",
    "        spotifyUserDatadf.loc[rowIndex,'acousticness'] = trackAudioFeaturesDict['acousticness']\n",
    "        spotifyUserDatadf.loc[rowIndex,'instrumentalness'] = trackAudioFeaturesDict['instrumentalness']\n",
    "        spotifyUserDatadf.loc[rowIndex,'liveness'] = trackAudioFeaturesDict['liveness']\n",
    "        spotifyUserDatadf.loc[rowIndex,'valence'] = trackAudioFeaturesDict['valence']\n",
    "        spotifyUserDatadf.loc[rowIndex,'tempo'] = trackAudioFeaturesDict['tempo']\n",
    "        spotifyUserDatadf.loc[rowIndex,'time_signature'] = trackAudioFeaturesDict['time_signature']\n",
    "\n",
    "       \n",
    "        \"\"\"\n",
    "        Accessing when the user played the current track by tapping into 'itemDict' dictionary\n",
    "        \"\"\"\n",
    "        spotifyUserDatadf.loc[rowIndex,'user_listening_datetime'] = itemDict['played_at']\n",
    "\n",
    "        \n",
    "    return spotifyUserDatadf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae80430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUserPersona(dataframe):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function definition: \n",
    "        This function creates the user's persona which represents the user's current mood/listening style. \n",
    "        The user persona is created by summarizing the user's listening history. This summarization process also\n",
    "        involved FEATURE ENGINEERING to add temporal information in order to give more weight to more recent\n",
    "        songs listened to\n",
    "\n",
    "    Arguments: \n",
    "        'dataframe' -- Dataframe containing pre-processed data from the user's Spotify account\n",
    "\n",
    "    Returns:\n",
    "        'userPersonadf' -- Dataframe containing user's summarized listening history\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This step will create a new column representing the weight of each song in the user's listening history\n",
    "    based on when the song was heard/listened to (today's date - date when the user listened to the song). \n",
    "    \n",
    "    Also convert today's date from local time zone to UTC since Spotify uses UTC time zone\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    \n",
    "    todays_datetime = datetime.datetime.today()\n",
    "    fromZone = tz.tzlocal()\n",
    "    toZone = tz.tzutc()\n",
    "    todays_datetime = todays_datetime.replace(tzinfo=fromZone)\n",
    "    todays_datetime_utc = todays_datetime.astimezone(toZone)\n",
    "    todays_date_utc = todays_datetime_utc.date()\n",
    "    \n",
    "    \n",
    "    dataframe['days_since_song_was_played'] = todays_date_utc - dataframe['user_listening_dateonly']\n",
    "    dataframe['days_since_song_was_played'] = dataframe['days_since_song_was_played'].astype('timedelta64[D]')\n",
    "    dataframe['days_since_song_was_played'] = dataframe['days_since_song_was_played'].astype(int)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    This step will add weights/recency-bias for each song based on when the song was heard/listened to \n",
    "    (today's date - date when the user listened to the song). \n",
    "    \n",
    "    The formula for adding recency-bias/weight is: weight = 1/((a+1)^weight_factor); where \"a\" is the \n",
    "    number of days since the song was played \n",
    "    \"\"\"\n",
    "    weight_factor = 2\n",
    "    dataframe['track_weight'] = dataframe['days_since_song_was_played'].apply(lambda x: 1/((x+1) ** weight_factor))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This step creates a 'weightedDataframe' dataframe which is created by multiplying the weight/recency-bias of each\n",
    "    song with all the elements of that song/track\n",
    "    \"\"\"\n",
    "    weightedDataframe = dataframe.loc[:,'danceability':'key_11'].mul(dataframe['track_weight'],0)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    This step creates the final 'userPersonadf' dataframe with just 1 row and 30 columns (one for each feature). This \n",
    "    1 row represents the final 'user vector'\n",
    "    \"\"\"\n",
    "   \n",
    "    userPersonadf = weightedDataframe.sum().div(len(dataframe)).to_frame().transpose()  \n",
    " \n",
    "    userPersonadf.reset_index(drop = True,inplace = True)\n",
    "    return userPersonadf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50005e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRecommendations(userPerona,spotifySongData,numberOfRecommendations = 10):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Function definition: \n",
    "        This function generates songs recommendations by using a similarity metric called 'cosine similarity'\n",
    "\n",
    "    Arguments: \n",
    "        'userPerona' -- Dataframe with a singular row (user vector) representing user's persona\n",
    "        'spotifySongData' -- Dataframe containing pre-processed Spotify data from the kaggle dataset \n",
    "        'numberOfRecommendations' -- Total number of recommendations to be produced. Default is 10\n",
    "\n",
    "    Returns:\n",
    "        'recommendations' -- Dataframe containing recommendations for the user\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    This step performs 4 different sub-steps\n",
    "    \n",
    "    1. Calculates 'cosine similarity' between the user persona vector and each element in the pre-processed  \n",
    "       kaggle Spotify dataset resulting in a matrix. This matrix ONLY contains the 'angular distance' between the\n",
    "       user persona vector and each song in the pre-processed kaggle dataset\n",
    "    \n",
    "    2. It then converts the resulting matrix to a pandas dataframe. This conversion step results in a dataframe with \n",
    "       n-number of columns (where n is the total number of elements in the pre-processed kaggle dataset)\n",
    "       and 1 row\n",
    "    \n",
    "    3. The conversion step is followed by a transposing step so that we have only 1 column and n-number of rows. \n",
    "       We want only 1 column so that it can be appneded to the dataframe representing the pre-processed kaggle dataset.\n",
    "       Appending this column will help us in sorting the dataset based on the value of 'cosine similarity' enabling\n",
    "       us to make the recommendations\n",
    "       \n",
    "    4. Naming the column after transposing and before appending\n",
    "    \"\"\"\n",
    "    \n",
    "    spotifySongData.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    cosineSimilarityMatrix = cosine_similarity(spotifySongData.loc[:,'danceability':'key_11'].values,userPerona.values)\n",
    "    cosineSimilaritydf = pd.DataFrame(cosineSimilarityMatrix) \n",
    "    cosineSimilaritydf.columns = ['cosine_similarity'] \n",
    "    spotifySongData['cosine_similarity'] = cosineSimilaritydf['cosine_similarity']\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    This step helps us make the song recommendations by sorting the dataset based on the value of 'cosine similarity'\n",
    "    \"\"\"\n",
    "    sortedSpotifySongData = spotifySongData.sort_values(by='cosine_similarity',ascending = False)\n",
    "    sortedSpotifySongData.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    recommendations = sortedSpotifySongData.head(numberOfRecommendations)\n",
    "    recommendations = recommendations[['track_id','track_name']]\n",
    "    \n",
    "    recommendations.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd14fc",
   "metadata": {},
   "source": [
    "## WORKING WITH THE KAGGLE'S SPOTIFY DATASET\n",
    "\n",
    "### 1. Import the dataset\n",
    "### 2. Perform data cleaning\n",
    "### 3. Perform data pre-processing (One-Hot Encoding and Data Scaling/Normalization)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb756951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "spotifyTracksDatasetdf = importSpotifyKaggleDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56770012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "cleanedSpotifyTracksDatasetdf = cleanSpotifyData(dataframe = spotifyTracksDatasetdf,\n",
    "                                                     datatype = 'kaggle_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9131a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3    \n",
    "processedSpotifyTracksDatasetdf, scaler= preProcessSpotifyData(dataframe = cleanedSpotifyTracksDatasetdf,\n",
    "                                                           datatype = 'kaggle_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32a264",
   "metadata": {},
   "source": [
    "## WORKING WITH THE USER'S SPOTIFY DATA\n",
    "\n",
    "### 1. Connect to the user's Spotify account\n",
    "### 2. Create a dataframe containing the user's Spotify listening history\n",
    "### 3. Perform data cleaning\n",
    "### 4. Perform data pre-processing (One-Hot Encoding and Data Scaling/Normalization)\n",
    "### 5. Create user's persona (user vector) representing their current musical taste (mood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a39a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "spotifyClientID = ''\n",
    "spotifySecret = ''\n",
    "spotifyRedirectUri = ''\n",
    "scope = ''\n",
    "userSpotifyClient = connectToUserSpotify(spotifyClientID,spotifySecret,\n",
    "                                         spotifyRedirectUri,scope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073765c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "spotifyUserDatadf = createSpotifyUserData(userSpotifyClient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aa6decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "cleanedSpotifyUserDatadf = cleanSpotifyData(dataframe = spotifyUserDatadf,\n",
    "                                                datatype = 'user_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a079d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "processedSpotifyUserDatadf = preProcessSpotifyData(dataframe = cleanedSpotifyUserDatadf,\n",
    "                                                      datatype = 'user_data',\n",
    "                                                      baselinedf = processedSpotifyTracksDatasetdf,\n",
    "                                                      preDefinedScaler = scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f50096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5\n",
    "userPersonadf = createUserPersona(dataframe = processedSpotifyUserDatadf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef75f4cd",
   "metadata": {},
   "source": [
    "## GENERATING RECOMMENDATIONS\n",
    "### 1. Perform pairwise comparison to compare user persona and songs from the Kaggle dataset by using 'cosine similarity' as the similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2ff58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = generateRecommendations(userPerona = userPersonadf,\n",
    "                         spotifySongData = processedSpotifyTracksDatasetdf,\n",
    "                           numberOfRecommendations = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "650d71b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3RK1WwfiDHAKHw5N7HetGq</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1WBpKHfjwfG9PjOe0m8H9U</td>\n",
       "      <td>Erzurum Yaylasıyam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3lBA4KEHNesOCKYE9J4ntM</td>\n",
       "      <td>Loppuviikko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2I0IqsRziPqef8UIVoo9r6</td>\n",
       "      <td>La Gente Esta Borracha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2fOjendzUzepHwR9QrVyYF</td>\n",
       "      <td>La Respuesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6DX3A1hDedL5EfmF9PrEDt</td>\n",
       "      <td>Everywhere I Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4Sy2utZ3u5mWnmu6LZHQkl</td>\n",
       "      <td>Cehennemin Dibi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0XWE43513Bldnr8DOqNiOO</td>\n",
       "      <td>Nagy Buli Lesz Minálunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0TyH4jFn7eeSJM4gfkql7h</td>\n",
       "      <td>Super Riddim Internacional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7v22aNI4265GCu0WNXG6MV</td>\n",
       "      <td>Que la violence stoppe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1mwVPal0tBguF6bkQbYyjT</td>\n",
       "      <td>Asla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6GhjK3Tv16mp2OJcGjMWzk</td>\n",
       "      <td>Tu Muere Aqui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4zkOTmiamebLJ39Sqbp7sb</td>\n",
       "      <td>Boom Boom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5RLBZePs33aN2F8uCzcSeo</td>\n",
       "      <td>Lindo Pero Bruto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0XinBYhf1X3kdvKQHOX971</td>\n",
       "      <td>Tú Me Dejaste De Querer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1OktfRhqVFilx7xBrao2Z4</td>\n",
       "      <td>5 Taara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0cjCEQqbJZwdRnxu3zWodj</td>\n",
       "      <td>Cosita Rica (Mami Tu Estas Dura) [with El Mich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5J7CCRViBdDq84j9iCDNhj</td>\n",
       "      <td>San Judas City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7JVIiaJPFiZypYSOMREhhA</td>\n",
       "      <td>Me Estas Tentando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2h4o6VODrblfyqZYAPoNaR</td>\n",
       "      <td>На раЁне</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2P3vQ0j3EgIRrHYh9qAyve</td>\n",
       "      <td>Winner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3VdDd3IWdd4Ll3pnmUMmfU</td>\n",
       "      <td>Da Jim Rap Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0wGrTrI43CKmfzbFNNhftb</td>\n",
       "      <td>East Side Flow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1wx8KiQBYO2CoOWIeZHznD</td>\n",
       "      <td>Katalliles Proipothesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5WwhPJ8CW2fkW6qXzLG4gq</td>\n",
       "      <td>U Got My Body - Original Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25GMPAuqLZr9wMubqPqM8c</td>\n",
       "      <td>Nebunia Lui Juvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5LHWMkeIXusuUcbp1CZl4n</td>\n",
       "      <td>Got to Be There - Oldskool Dub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22k8cAljnu78XhnPe7Sbcx</td>\n",
       "      <td>В ръцете на друг</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2W0VenqvlMW4c65YsxT5zu</td>\n",
       "      <td>Morena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0RTUDjc3FeUaMQ6LOSA2c9</td>\n",
       "      <td>Je Raakt Me Zo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7xxINB0dslPUNQrWWQmlLz</td>\n",
       "      <td>Mała Figlarka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5c3mUtkS8FvumKaVkcpB0H</td>\n",
       "      <td>Baby Doll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5Y2JJqEUgp1I9HauCYPsob</td>\n",
       "      <td>Jeevitame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0lqQLZR1bYey6sVOA2K8il</td>\n",
       "      <td>Nebunia Lui Juvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4hbimRSQ2ZA5F86WSw5p6S</td>\n",
       "      <td>Kawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6DFB92Y9FOkjCC9oVPlkVN</td>\n",
       "      <td>いちご畑でつかまえて</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2y0ee1wuzrrZmBTZw2ztaa</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5swIQ4Q0YyQVYBe5qTvv0b</td>\n",
       "      <td>Extraño Tu Amor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>50XhNU516Z7z8ZP8FHdwd4</td>\n",
       "      <td>シアワセナラテヲタタコウ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1vvNmPOiUuyCbgWmtc6yfm</td>\n",
       "      <td>My Way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4PML5RtrVcYAwTTS46otXB</td>\n",
       "      <td>Vaathi Raid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6IQkc9xHpZ0CFF9SXrPwK4</td>\n",
       "      <td>Uykusuz Her Gece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4cjoZb33Fk1dZYrIRMg8Q6</td>\n",
       "      <td>Mirchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>693359DlfpvoEfIYleKs05</td>\n",
       "      <td>Endhuko Pichi Pichi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0JsevMNlsPLe1J4rnAHUBh</td>\n",
       "      <td>Peter Son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>05dYneZZZ2mytSmnsvzFoW</td>\n",
       "      <td>Gangu Leader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6Isn9Z4uG99J5f99Z5Clua</td>\n",
       "      <td>Skavanker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1i1vBILMIPrdSykyIHS6JV</td>\n",
       "      <td>Sambel Terasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6HTGDw9N6uGlz9KcrDTQkW</td>\n",
       "      <td>Fari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>7MtK3lPdVPq2WGO6EWHB9V</td>\n",
       "      <td>Dharala Prabhu Title Track</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id                                         track_name\n",
       "0   3RK1WwfiDHAKHw5N7HetGq                                               Love\n",
       "1   1WBpKHfjwfG9PjOe0m8H9U                                 Erzurum Yaylasıyam\n",
       "2   3lBA4KEHNesOCKYE9J4ntM                                        Loppuviikko\n",
       "3   2I0IqsRziPqef8UIVoo9r6                             La Gente Esta Borracha\n",
       "4   2fOjendzUzepHwR9QrVyYF                                       La Respuesta\n",
       "5   6DX3A1hDedL5EfmF9PrEDt                                    Everywhere I Go\n",
       "6   4Sy2utZ3u5mWnmu6LZHQkl                                    Cehennemin Dibi\n",
       "7   0XWE43513Bldnr8DOqNiOO                            Nagy Buli Lesz Minálunk\n",
       "8   0TyH4jFn7eeSJM4gfkql7h                         Super Riddim Internacional\n",
       "9   7v22aNI4265GCu0WNXG6MV                             Que la violence stoppe\n",
       "10  1mwVPal0tBguF6bkQbYyjT                                               Asla\n",
       "11  6GhjK3Tv16mp2OJcGjMWzk                                      Tu Muere Aqui\n",
       "12  4zkOTmiamebLJ39Sqbp7sb                                          Boom Boom\n",
       "13  5RLBZePs33aN2F8uCzcSeo                                   Lindo Pero Bruto\n",
       "14  0XinBYhf1X3kdvKQHOX971                            Tú Me Dejaste De Querer\n",
       "15  1OktfRhqVFilx7xBrao2Z4                                            5 Taara\n",
       "16  0cjCEQqbJZwdRnxu3zWodj  Cosita Rica (Mami Tu Estas Dura) [with El Mich...\n",
       "17  5J7CCRViBdDq84j9iCDNhj                                     San Judas City\n",
       "18  7JVIiaJPFiZypYSOMREhhA                                  Me Estas Tentando\n",
       "19  2h4o6VODrblfyqZYAPoNaR                                           На раЁне\n",
       "20  2P3vQ0j3EgIRrHYh9qAyve                                             Winner\n",
       "21  3VdDd3IWdd4Ll3pnmUMmfU                                    Da Jim Rap Thai\n",
       "22  0wGrTrI43CKmfzbFNNhftb                                     East Side Flow\n",
       "23  1wx8KiQBYO2CoOWIeZHznD                            Katalliles Proipothesis\n",
       "24  5WwhPJ8CW2fkW6qXzLG4gq                       U Got My Body - Original Mix\n",
       "25  25GMPAuqLZr9wMubqPqM8c                                  Nebunia Lui Juvel\n",
       "26  5LHWMkeIXusuUcbp1CZl4n                     Got to Be There - Oldskool Dub\n",
       "27  22k8cAljnu78XhnPe7Sbcx                                   В ръцете на друг\n",
       "28  2W0VenqvlMW4c65YsxT5zu                                             Morena\n",
       "29  0RTUDjc3FeUaMQ6LOSA2c9                                     Je Raakt Me Zo\n",
       "30  7xxINB0dslPUNQrWWQmlLz                                      Mała Figlarka\n",
       "31  5c3mUtkS8FvumKaVkcpB0H                                          Baby Doll\n",
       "32  5Y2JJqEUgp1I9HauCYPsob                                          Jeevitame\n",
       "33  0lqQLZR1bYey6sVOA2K8il                                  Nebunia Lui Juvel\n",
       "34  4hbimRSQ2ZA5F86WSw5p6S                                             Kawaii\n",
       "35  6DFB92Y9FOkjCC9oVPlkVN                                         いちご畑でつかまえて\n",
       "36  2y0ee1wuzrrZmBTZw2ztaa                                              Total\n",
       "37  5swIQ4Q0YyQVYBe5qTvv0b                                    Extraño Tu Amor\n",
       "38  50XhNU516Z7z8ZP8FHdwd4                                       シアワセナラテヲタタコウ\n",
       "39  1vvNmPOiUuyCbgWmtc6yfm                                             My Way\n",
       "40  4PML5RtrVcYAwTTS46otXB                                        Vaathi Raid\n",
       "41  6IQkc9xHpZ0CFF9SXrPwK4                                   Uykusuz Her Gece\n",
       "42  4cjoZb33Fk1dZYrIRMg8Q6                                             Mirchi\n",
       "43  693359DlfpvoEfIYleKs05                                Endhuko Pichi Pichi\n",
       "44  0JsevMNlsPLe1J4rnAHUBh                                          Peter Son\n",
       "45  05dYneZZZ2mytSmnsvzFoW                                       Gangu Leader\n",
       "46  6Isn9Z4uG99J5f99Z5Clua                                          Skavanker\n",
       "47  1i1vBILMIPrdSykyIHS6JV                                      Sambel Terasi\n",
       "48  6HTGDw9N6uGlz9KcrDTQkW                                               Fari\n",
       "49  7MtK3lPdVPq2WGO6EWHB9V                         Dharala Prabhu Title Track"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
